import { useState, useRef, useEffect, useCallback } from "react";
import { X, Send, Bot, User, Loader2, Sparkles, Globe, Mic, MicOff, Volume2, VolumeX } from "lucide-react";
import { cn } from "@/lib/utils";
import { toast } from "sonner";

interface Message {
  role: "user" | "assistant";
  content: string;
}

type Language = "bn" | "en" | "hi";

const languageConfig = {
  bn: {
    name: "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ",
    flag: "üáßüá©",
    welcome: "‡¶π‡ßç‡¶Ø‡¶æ‡¶≤‡ßã! üëã ‡¶ö‡¶ø‡¶§‡ßç‡¶∞‡¶æ‡¶¨‡¶≤‡ßÄ‡¶§‡ßá ‡¶∏‡ßç‡¶¨‡¶æ‡¶ó‡¶§‡¶Æ! ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ AI ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶ï‡•§ ‡¶Ü‡¶ú ‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶ï‡ßÄ‡¶≠‡¶æ‡¶¨‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø?",
    placeholder: "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶∞‡ßç‡¶§‡¶æ ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶®...",
    online: "‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶®",
    listening: "‡¶∂‡ßÅ‡¶®‡¶õ‡¶ø...",
    processing: "‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ï‡¶∞‡¶£...",
    speaking: "‡¶¨‡¶≤‡¶õ‡¶ø..."
  },
  en: {
    name: "English",
    flag: "üá¨üáß",
    welcome: "Hello! üëã Welcome to Chitraboli ‡¶ö‡¶ø‡¶§‡ßç‡¶∞‡¶æ‡¶¨‡¶≤‡ßÄ! I'm your AI assistant. How can I help you today?",
    placeholder: "Type your message...",
    online: "Online",
    listening: "Listening...",
    processing: "Processing...",
    speaking: "Speaking..."
  },
  hi: {
    name: "‡§π‡§ø‡§Ç‡§¶‡•Ä",
    flag: "üáÆüá≥",
    welcome: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! üëã ‡§ö‡§ø‡§§‡•ç‡§∞‡§æ‡§¨‡•ã‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•Ç‡§Ç‡•§ ‡§Ü‡§ú ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?",
    placeholder: "‡§Ö‡§™‡§®‡§æ ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§≤‡§ø‡§ñ‡•á‡§Ç...",
    online: "‡§ë‡§®‡§≤‡§æ‡§á‡§®",
    listening: "‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...",
    processing: "‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó...",
    speaking: "‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç..."
  }
};

const quickReplies = {
  bn: [
    { label: "üì¶ ‡¶™‡¶£‡ßç‡¶Ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®", message: "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ú‡¶®‡¶™‡ßç‡¶∞‡¶ø‡¶Ø‡¶º ‡¶™‡¶£‡ßç‡¶Ø‡¶ó‡ßÅ‡¶≤‡ßã ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®" },
    { label: "üîç ‡¶Ö‡¶∞‡ßç‡¶°‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï", message: "‡¶Ü‡¶Æ‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Ö‡¶∞‡ßç‡¶°‡¶æ‡¶∞ ‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á" },
    { label: "üìû ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó", message: "‡¶Ü‡¶™‡¶®‡¶æ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶¨?" },
    { label: "üí≥ ‡¶™‡ßá‡¶Æ‡ßá‡¶®‡ßç‡¶ü", message: "‡¶ï‡¶ø ‡¶ï‡¶ø ‡¶™‡ßá‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶Ö‡¶™‡¶∂‡¶® ‡¶Ü‡¶õ‡ßá?" }
  ],
  en: [
    { label: "üì¶ Show Products", message: "Show me your popular products" },
    { label: "üîç Track Order", message: "I want to track my order" },
    { label: "üìû Contact Us", message: "How can I contact you?" },
    { label: "üí≥ Payment", message: "What payment options do you have?" }
  ],
  hi: [
    { label: "üì¶ ‡§â‡§§‡•ç‡§™‡§æ‡§¶ ‡§¶‡•á‡§ñ‡•á‡§Ç", message: "‡§Ö‡§™‡§®‡•á ‡§≤‡•ã‡§ï‡§™‡•ç‡§∞‡§ø‡§Ø ‡§â‡§§‡•ç‡§™‡§æ‡§¶ ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç" },
    { label: "üîç ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§ü‡•ç‡§∞‡•à‡§ï", message: "‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡§æ ‡§ë‡§∞‡•ç‡§°‡§∞ ‡§ü‡•ç‡§∞‡•à‡§ï ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡§æ ‡§π‡•Ç‡§Ç" },
    { label: "üìû ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï", message: "‡§Ü‡§™‡§∏‡•á ‡§ï‡•à‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç?" },
    { label: "üí≥ ‡§≠‡•Å‡§ó‡§§‡§æ‡§®", message: "‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§ï‡•å‡§® ‡§∏‡•á ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§µ‡§ø‡§ï‡§≤‡•ç‡§™ ‡§π‡•à‡§Ç?" }
  ]
};

export const AIAssistant = () => {
  const [isOpen, setIsOpen] = useState(false);
  const [language, setLanguage] = useState<Language>("bn");
  const [showLanguageMenu, setShowLanguageMenu] = useState(false);
  const [messages, setMessages] = useState<Message[]>([{
    role: "assistant",
    content: languageConfig.bn.welcome
  }]);
  const [input, setInput] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [speakingIndex, setSpeakingIndex] = useState<number | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const audioRef = useRef<HTMLAudioElement | null>(null);
  // Cache TTS audio URLs by content hash to avoid repeated API calls
  const ttsCache = useRef<Map<string, string>>(new Map());

  const handleLanguageChange = (lang: Language) => {
    setLanguage(lang);
    setShowLanguageMenu(false);
    setMessages([{
      role: "assistant",
      content: languageConfig[lang].welcome
    }]);
  };

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({
      behavior: "smooth"
    });
  }, [messages]);

  // Cleanup audio on unmount
  useEffect(() => {
    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }
      // Revoke cached audio URLs
      ttsCache.current.forEach((url) => URL.revokeObjectURL(url));
      ttsCache.current.clear();
    };
  }, []);

  const sendMessage = async (messageText?: string) => {
    const textToSend = messageText || input.trim();
    if (!textToSend || isLoading) return;
    
    const userMessage: Message = {
      role: "user",
      content: textToSend
    };
    setMessages(prev => [...prev, userMessage]);
    setInput("");
    setIsLoading(true);
    let assistantContent = "";
    
    try {
      const response = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/ai-chat`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`
        },
        body: JSON.stringify({
          language,
          messages: [...messages, userMessage].map(m => ({
            role: m.role,
            content: m.content
          }))
        })
      });
      
      if (!response.ok) {
        throw new Error("Failed to get response");
      }
      
      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      if (!reader) throw new Error("No reader");
      
      setMessages(prev => [...prev, {
        role: "assistant",
        content: ""
      }]);
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split("\n");
        
        for (const line of lines) {
          if (line.startsWith("data: ")) {
            const data = line.slice(6).trim();
            if (data === "[DONE]") continue;
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                assistantContent += content;
                setMessages(prev => {
                  const newMessages = [...prev];
                  newMessages[newMessages.length - 1] = {
                    role: "assistant",
                    content: assistantContent
                  };
                  return newMessages;
                });
              }
            } catch {
              // Skip invalid JSON
            }
          }
        }
      }
    } catch (error) {
      console.error("Chat error:", error);
      setMessages(prev => [...prev, {
        role: "assistant",
        content: language === "bn" 
          ? "‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§, ‡¶è‡¶ñ‡¶® ‡¶∏‡¶æ‡¶°‡¶º‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶¨‡¶æ WhatsApp-‡¶è ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"
          : language === "hi"
          ? "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Ö‡§≠‡•Ä ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç ‡§Ø‡§æ WhatsApp ‡§™‡§∞ ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§"
          : "I apologize, but I'm having trouble responding right now. Please try again or contact us via WhatsApp."
      }]);
    } finally {
      setIsLoading(false);
    }
  };

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach(track => track.stop());
        
        if (audioChunksRef.current.length === 0) return;
        
        setIsProcessingVoice(true);
        
        try {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          
          // Convert to base64
          const reader = new FileReader();
          reader.readAsDataURL(audioBlob);
          
          reader.onloadend = async () => {
            const base64Audio = (reader.result as string).split(',')[1];
            
            try {
              const response = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/voice-to-text`, {
                method: 'POST',
                headers: {
                  'Content-Type': 'application/json',
                  Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`
                },
                body: JSON.stringify({ audio: base64Audio, language })
              });
              
              if (!response.ok) {
                throw new Error('Failed to transcribe audio');
              }
              
              const { text, error } = await response.json();
              
              if (error) {
                throw new Error(error);
              }
              
              if (text && text.trim()) {
                setInput(text);
                // Auto-send the transcribed message
                await sendMessage(text);
              } else {
                toast.error(language === "bn" ? "‡¶ï‡ßã‡¶®‡ßã ‡¶ï‡¶•‡¶æ ‡¶¨‡ßã‡¶ù‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø" : language === "hi" ? "‡§ï‡•ã‡§à ‡§¨‡§æ‡§§ ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§à" : "Could not understand speech");
              }
            } catch (error) {
              console.error('Transcription error:', error);
              toast.error(language === "bn" ? "‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ" : language === "hi" ? "‡§Ü‡§µ‡§æ‡§ú ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ" : "Failed to process voice");
            } finally {
              setIsProcessingVoice(false);
            }
          };
        } catch (error) {
          console.error('Audio processing error:', error);
          setIsProcessingVoice(false);
          toast.error("Failed to process audio");
        }
      };
      
      mediaRecorder.start();
      setIsRecording(true);
      
    } catch (error) {
      console.error('Microphone access error:', error);
      toast.error(language === "bn" ? "‡¶Æ‡¶æ‡¶á‡¶ï‡ßç‡¶∞‡ßã‡¶´‡ßã‡¶® ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶∏‡ßá‡¶∏ ‡¶¶‡¶ø‡¶®" : language === "hi" ? "‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§¶‡•á‡§Ç" : "Please allow microphone access");
    }
  }, [language]);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  }, [isRecording]);

  const toggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const speakWithBrowserTTS = (text: string) => {
    if (!('speechSynthesis' in window)) {
      toast.error(language === "bn" ? "‡¶è‡¶á ‡¶¨‡ßç‡¶∞‡¶æ‡¶â‡¶ú‡¶æ‡¶∞‡ßá TTS ‡¶∏‡¶æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶®‡ßá‡¶á" : language === "hi" ? "‡§á‡§∏ ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ ‡§Æ‡•á‡§Ç TTS ‡§∏‡§™‡•ã‡§∞‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à" : "TTS is not supported in this browser");
      return;
    }

    // Cancel any previous speech
    window.speechSynthesis.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = language === 'bn' ? 'bn-BD' : language === 'hi' ? 'hi-IN' : 'en-US';
    utterance.rate = 0.95;

    utterance.onend = () => {
      setIsSpeaking(false);
      setSpeakingIndex(null);
    };

    utterance.onerror = () => {
      setIsSpeaking(false);
      setSpeakingIndex(null);
      toast.error(language === "bn" ? "‡¶∏‡ßç‡¶™‡¶ø‡¶ö ‡¶ö‡¶æ‡¶≤‡¶æ‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ" : language === "hi" ? "‡§∏‡•ç‡§™‡•Ä‡§ö ‡§ö‡§≤‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ" : "Failed to play speech");
    };

    window.speechSynthesis.speak(utterance);
  };

  const speakText = async (text: string, messageIndex: number) => {
    // Stop any currently playing audio
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current = null;
    }

    // Stop any currently speaking browser TTS
    if ('speechSynthesis' in window && window.speechSynthesis.speaking) {
      window.speechSynthesis.cancel();
    }

    // If clicking the same message that's speaking, stop it
    if (speakingIndex === messageIndex && isSpeaking) {
      setIsSpeaking(false);
      setSpeakingIndex(null);
      return;
    }

    // Create a cache key from text + language
    const cacheKey = `${language}:${text}`;
    const cachedUrl = ttsCache.current.get(cacheKey);

    // Helper to play audio from a URL
    const playFromUrl = (audioUrl: string, revokeOnEnd: boolean) => {
      const audio = new Audio(audioUrl);
      audioRef.current = audio;

      audio.onended = () => {
        setIsSpeaking(false);
        setSpeakingIndex(null);
        audioRef.current = null;
        if (revokeOnEnd) {
          URL.revokeObjectURL(audioUrl);
        }
      };

      audio.onerror = () => {
        setIsSpeaking(false);
        setSpeakingIndex(null);
        audioRef.current = null;
        if (revokeOnEnd) {
          URL.revokeObjectURL(audioUrl);
        }
        toast.error(language === "bn" ? "‡¶Ö‡¶°‡¶ø‡¶ì ‡¶™‡ßç‡¶≤‡ßá ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ" : language === "hi" ? "‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ö‡§≤‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ" : "Failed to play audio");
      };

      audio.play();
    };

    // If cached, play directly
    if (cachedUrl) {
      setIsSpeaking(true);
      setSpeakingIndex(messageIndex);
      playFromUrl(cachedUrl, false);
      return;
    }

    try {
      setIsSpeaking(true);
      setSpeakingIndex(messageIndex);

      const response = await fetch(`${import.meta.env.VITE_SUPABASE_URL}/functions/v1/elevenlabs-tts`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY}`
        },
        body: JSON.stringify({ text, language })
      });

      const contentType = response.headers.get('content-type') || '';

      // ElevenLabs may return JSON (even with HTTP 200) when Free Tier is blocked.
      if (contentType.includes('application/json')) {
        let err: any = null;
        try {
          err = await response.json();
        } catch {
          // ignore
        }

        const msg = (err?.error as string | undefined) || (language === "bn" ? "‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏ ‡¶∏‡¶æ‡¶Æ‡¶Ø‡¶º‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶®‡¶Ø‡¶º" : language === "hi" ? "‡§µ‡•â‡§Ø‡§∏ ‡§∏‡•á‡§µ‡§æ ‡§Ö‡§≠‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à" : "Voice service is temporarily unavailable");
        const code = err?.code as string | undefined;

        const isUnusualActivity =
          code === 'detected_unusual_activity' ||
          (typeof msg === 'string' && msg.toLowerCase().includes('unusual activity'));

        if (isUnusualActivity) {
          toast.error(
            language === "bn"
              ? "ElevenLabs ‡¶´‡ßç‡¶∞‡¶ø ‡¶ü‡¶ø‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶¨‡ßç‡¶≤‡¶ï ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá (VPN/‡¶™‡ßç‡¶≤‡ßç‡¶Ø‡¶æ‡¶® ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ)‡•§ ‡¶¨‡ßá‡¶∏‡¶ø‡¶ï ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§"
              : language === "hi"
              ? "ElevenLabs ‡§´‡•ç‡§∞‡•Ä ‡§ü‡§ø‡§Ø‡§∞ ‡§¨‡•ç‡§≤‡•â‡§ï ‡§π‡•à (VPN/‡§™‡•ç‡§≤‡§æ‡§®)‡•§ ‡§¨‡•á‡§∏‡§ø‡§ï ‡§µ‡•â‡§Ø‡§∏ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‡•§"
              : "ElevenLabs Free Tier is blocked (VPN/plan). Using basic voice instead."
          );

          speakWithBrowserTTS(text);
          return;
        }

        throw new Error(msg);
      }

      if (!response.ok) {
        throw new Error(language === "bn" ? "‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶ø‡¶∏ ‡¶∏‡¶æ‡¶Æ‡¶Ø‡¶º‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ‡¶â‡¶™‡¶≤‡¶¨‡ßç‡¶ß ‡¶®‡¶Ø‡¶º" : language === "hi" ? "‡§µ‡•â‡§Ø‡§∏ ‡§∏‡•á‡§µ‡§æ ‡§Ö‡§≠‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à" : "Voice service is temporarily unavailable");
      }

      // Audio success path (binary response)
      const audioBlob = await response.blob();
      const audioUrl = URL.createObjectURL(audioBlob);

      // Cache the audio URL for future playback
      ttsCache.current.set(cacheKey, audioUrl);

      playFromUrl(audioUrl, false);
    } catch (error) {
      console.error('TTS error:', error);

      // Last-resort fallback for any other error
      setIsSpeaking(true);
      setSpeakingIndex(messageIndex);
      speakWithBrowserTTS(text);
    }
  };

  return (
    <div className="relative">
      {/* Toggle Button - positioned within footer */}
      <button
        onClick={() => setIsOpen(!isOpen)}
        className={cn(
          "flex items-center gap-2 px-4 py-2 rounded-full",
          "bg-gradient-to-br from-purple-accent to-purple-accent/80",
          "shadow-[0_0_20px_rgba(139,92,246,0.4)]",
          "transition-all duration-300 hover:scale-105",
          "text-white text-sm font-medium"
        )}
        aria-label="Toggle AI Assistant"
      >
        <Sparkles className="w-5 h-5" />
        <span>AI Assistant</span>
        {!isOpen && <span className="w-2 h-2 bg-gold rounded-full animate-pulse" />}
      </button>

      {/* Chat Window - positioned above button within footer container */}
      <div
        className={cn(
          "absolute bottom-full right-0 mb-3",
          "w-[340px] sm:w-[380px] h-[400px] sm:h-[450px]",
          "bg-card/95 backdrop-blur-xl rounded-2xl",
          "border border-purple-accent/30",
          "shadow-[0_0_40px_rgba(139,92,246,0.3)]",
          "flex flex-col overflow-hidden",
          "transition-all duration-300",
          isOpen ? "opacity-100 scale-100 translate-y-0" : "opacity-0 scale-95 translate-y-4 pointer-events-none"
        )}
      >
        {/* Header */}
        <div className="p-3 bg-gradient-to-r from-purple-accent/20 to-gold/10 border-b border-purple-accent/20">
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-2">
              <div className="w-8 h-8 rounded-full bg-gradient-to-br from-purple-accent to-gold flex items-center justify-center">
                <Bot className="w-4 h-4 text-white" />
              </div>
              <div>
                <h3 className="font-display text-sm text-foreground">Chitraboli AI</h3>
                <p className="text-xs text-green-400 flex items-center gap-1">
                  <span className="w-1.5 h-1.5 rounded-full bg-green-400 animate-pulse" />
                  {isRecording 
                    ? languageConfig[language].listening 
                    : isProcessingVoice 
                    ? languageConfig[language].processing 
                    : languageConfig[language].online}
                </p>
              </div>
            </div>
            <div className="flex items-center gap-1">
              {/* Language Selector */}
              <div className="relative">
                <button
                  onClick={() => setShowLanguageMenu(!showLanguageMenu)}
                  className="w-7 h-7 rounded-full bg-muted/50 flex items-center justify-center hover:bg-muted transition-colors text-xs"
                  title="Change Language"
                >
                  <Globe className="w-3.5 h-3.5" />
                </button>
                {showLanguageMenu && (
                  <div className="absolute right-0 top-full mt-1 bg-card border border-purple-accent/30 rounded-lg shadow-xl z-50 overflow-hidden min-w-[120px]">
                    {(Object.keys(languageConfig) as Language[]).map((lang) => (
                      <button
                        key={lang}
                        onClick={() => handleLanguageChange(lang)}
                        className={cn(
                          "w-full px-3 py-2 text-left text-xs flex items-center gap-2 hover:bg-muted/50 transition-colors",
                          language === lang && "bg-purple-accent/20 text-purple-accent"
                        )}
                      >
                        <span>{languageConfig[lang].flag}</span>
                        <span>{languageConfig[lang].name}</span>
                      </button>
                    ))}
                  </div>
                )}
              </div>
              <button
                onClick={() => setIsOpen(false)}
                className="w-7 h-7 rounded-full bg-muted/50 flex items-center justify-center hover:bg-muted transition-colors"
              >
                <X className="w-4 h-4" />
              </button>
            </div>
          </div>
        </div>

        {/* Messages */}
        <div className="flex-1 overflow-y-auto p-3 space-y-3">
          {messages.map((message, index) => (
            <div key={index} className={cn("flex gap-2", message.role === "user" && "flex-row-reverse")}>
              <div className={cn(
                "w-7 h-7 rounded-full flex-shrink-0 flex items-center justify-center",
                message.role === "assistant" ? "bg-gradient-to-br from-purple-accent to-gold" : "bg-gold/20"
              )}>
                {message.role === "assistant" ? <Bot className="w-3.5 h-3.5 text-white" /> : <User className="w-3.5 h-3.5 text-gold" />}
              </div>
              <div className="flex flex-col gap-1 max-w-[80%]">
                <div className={cn(
                  "p-2.5 rounded-xl",
                  message.role === "assistant" ? "bg-muted/50 rounded-tl-sm" : "bg-gradient-to-r from-purple-accent/20 to-gold/20 rounded-tr-sm"
                )}>
                  <p className="text-xs text-foreground whitespace-pre-wrap">{message.content}</p>
                </div>
                {/* TTS button for assistant messages */}
                {message.role === "assistant" && message.content && (
                  <button
                    onClick={() => speakText(message.content, index)}
                    disabled={isLoading}
                    className={cn(
                      "self-start flex items-center gap-1 px-2 py-1 rounded-full text-xs transition-all",
                      speakingIndex === index && isSpeaking
                        ? "bg-purple-accent/30 text-purple-accent"
                        : "bg-muted/30 hover:bg-muted/50 text-muted-foreground hover:text-foreground"
                    )}
                    title={speakingIndex === index && isSpeaking 
                      ? (language === "bn" ? "‡¶•‡¶æ‡¶Æ‡¶æ‡¶®" : language === "hi" ? "‡§∞‡•ã‡§ï‡•á‡§Ç" : "Stop") 
                      : (language === "bn" ? "‡¶∂‡ßÅ‡¶®‡ßÅ‡¶®" : language === "hi" ? "‡§∏‡•Å‡§®‡•á‡§Ç" : "Listen")}
                  >
                    {speakingIndex === index && isSpeaking ? (
                      <>
                        <VolumeX className="w-3 h-3" />
                        <span>{language === "bn" ? "‡¶•‡¶æ‡¶Æ‡¶æ‡¶®" : language === "hi" ? "‡§∞‡•ã‡§ï‡•á‡§Ç" : "Stop"}</span>
                      </>
                    ) : (
                      <>
                        <Volume2 className="w-3 h-3" />
                        <span>{language === "bn" ? "‡¶∂‡ßÅ‡¶®‡ßÅ‡¶®" : language === "hi" ? "‡§∏‡•Å‡§®‡•á‡§Ç" : "Listen"}</span>
                      </>
                    )}
                  </button>
                )}
              </div>
            </div>
          ))}
          {isLoading && messages[messages.length - 1]?.role !== "assistant" && (
            <div className="flex gap-2">
              <div className="w-7 h-7 rounded-full bg-gradient-to-br from-purple-accent to-gold flex items-center justify-center">
                <Bot className="w-3.5 h-3.5 text-white" />
              </div>
              <div className="bg-muted/50 p-2.5 rounded-xl rounded-tl-sm">
                <Loader2 className="w-4 h-4 animate-spin text-purple-accent" />
              </div>
            </div>
          )}
          <div ref={messagesEndRef} />
          
          {/* Quick Reply Buttons */}
          {messages.length <= 2 && !isLoading && (
            <div className="flex flex-wrap gap-1.5 pt-2">
              {quickReplies[language].map((reply, idx) => (
                <button
                  key={idx}
                  onClick={() => sendMessage(reply.message)}
                  className="px-2.5 py-1.5 text-xs bg-purple-accent/10 hover:bg-purple-accent/20 border border-purple-accent/30 rounded-full transition-colors text-foreground"
                >
                  {reply.label}
                </button>
              ))}
            </div>
          )}
        </div>

        {/* Input */}
        <div className="p-3 border-t border-purple-accent/20">
          <div className="flex gap-2">
            {/* Voice Input Button */}
            <button
              onClick={toggleRecording}
              disabled={isLoading || isProcessingVoice}
              className={cn(
                "w-8 h-8 rounded-full flex items-center justify-center transition-all",
                isRecording 
                  ? "bg-red-500 animate-pulse" 
                  : isProcessingVoice
                  ? "bg-yellow-500"
                  : "bg-muted/50 hover:bg-purple-accent/30",
                (isLoading || isProcessingVoice) && "opacity-50 cursor-not-allowed"
              )}
              title={isRecording ? "Stop recording" : "Voice input"}
            >
              {isRecording ? (
                <MicOff className="w-3.5 h-3.5 text-white" />
              ) : isProcessingVoice ? (
                <Loader2 className="w-3.5 h-3.5 text-white animate-spin" />
              ) : (
                <Mic className="w-3.5 h-3.5 text-foreground" />
              )}
            </button>
            
            <input
              type="text"
              value={input}
              onChange={e => setInput(e.target.value)}
              onKeyDown={e => e.key === "Enter" && sendMessage()}
              placeholder={languageConfig[language].placeholder}
              className="flex-1 bg-muted/50 border border-purple-accent/20 rounded-full px-3 py-2 text-xs focus:outline-none focus:border-purple-accent/50 transition-colors"
              disabled={isRecording || isProcessingVoice}
            />
            <button
              onClick={() => sendMessage()}
              disabled={!input.trim() || isLoading || isRecording || isProcessingVoice}
              className="w-8 h-8 rounded-full bg-gradient-to-br from-purple-accent to-gold flex items-center justify-center disabled:opacity-50 transition-opacity"
            >
              <Send className="w-3.5 h-3.5 text-white" />
            </button>
          </div>
        </div>
      </div>
    </div>
  );
};
